{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet for CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "832a2d41de75416099ab80ed75e44fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a21b738373df4f42b03c70678f461e1d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d28be25121641a484c7f4a83d98bad2",
              "IPY_MODEL_7e4fddf24dac4abda16f7f0aa3fb0b83"
            ]
          }
        },
        "a21b738373df4f42b03c70678f461e1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d28be25121641a484c7f4a83d98bad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57da882f0f7347c2b77866bf490c1ac8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ddf5c7b0cbb4df89fb50af96dc85a2d"
          }
        },
        "7e4fddf24dac4abda16f7f0aa3fb0b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c743b3d77bf345cab4e5bfff7951551b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:40&lt;00:00, 14522364.31it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cbcc182d272487c84219b417869d691"
          }
        },
        "57da882f0f7347c2b77866bf490c1ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ddf5c7b0cbb4df89fb50af96dc85a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c743b3d77bf345cab4e5bfff7951551b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cbcc182d272487c84219b417869d691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nix07/DenseNet-on-CIFAR10/blob/master/DenseNet_for_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI4LBkw3WRiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import math\n",
        "import pickle\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.onnx\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-CkjQeEG8tl",
        "colab_type": "text"
      },
      "source": [
        "## DenseNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERt5MbGmV2lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    \"\"\"\n",
        "    A class used to represent the bottleneck architecture.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    in_planes   => Number on input channels\n",
        "    growth_rate => Fixed number of feature maps in the dense block\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_planes, growth_rate):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = nn.Conv2d(in_planes, 4*growth_rate, kernel_size=1, \n",
        "                               bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n",
        "        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, \n",
        "                               padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(F.relu(self.bn1(x)))\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out = torch.cat([out,x], 1)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiO0fX6ZWP2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transition(nn.Module):\n",
        "    \"\"\"\n",
        "    A class to represent the Transition Block which reduces the features maps\n",
        "    between two Dense Blocks. It acts as down sampler.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    in_planes  => Number of input channels.\n",
        "    out_planes => Number of channels produced by the convolution.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_planes, out_planes):\n",
        "        super(Transition, self).__init__()\n",
        "        self.bn = nn.BatchNorm2d(in_planes)\n",
        "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(F.relu(self.bn(x)))\n",
        "        out = F.avg_pool2d(out, 2)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocj3nvKZWy-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DenseNet(nn.Module):\n",
        "    \"\"\"\n",
        "    A class to represent the DenseNet model.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    denseLayer  => Represents the type of dense layer used in Dense Block, i.e. Bottleneck.\n",
        "    nblocks     => Number of layers in each Dense Block.\n",
        "    growth_rate => Fixed number of feature maps in the dense block.\n",
        "    reduction   => Reduction factor for number of feature maps.\n",
        "    num_classes => Number of output classes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, denseLayer, nblocks, growth_rate=12, reduction=0.5, \n",
        "                 num_classes=10):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.growth_rate = growth_rate\n",
        "\n",
        "        num_planes = 2*growth_rate\n",
        "\n",
        "        # Initial Convolution layer of DenseNet.\n",
        "        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, \n",
        "                               bias=False)\n",
        "\n",
        "        ## A first pair of Dense Block and Transition Block where the number of\n",
        "        ## layers in the Dense Block are 6.\n",
        "        self.dense1 = self._make_dense_layers(denseLayer, num_planes, nblocks[0])\n",
        "        num_planes += nblocks[0]*growth_rate\n",
        "        out_planes = int(math.floor(num_planes*reduction))\n",
        "        self.trans1 = Transition(num_planes, out_planes)\n",
        "        num_planes = out_planes\n",
        "\n",
        "        ## A second pair of Dense Block and Transition Block where the number of\n",
        "        ## layers in the Dense Block are 12.\n",
        "        self.dense2 = self._make_dense_layers(denseLayer, num_planes, nblocks[1])\n",
        "        num_planes += nblocks[1]*growth_rate\n",
        "        out_planes = int(math.floor(num_planes*reduction))\n",
        "        self.trans2 = Transition(num_planes, out_planes)\n",
        "        num_planes = out_planes\n",
        "\n",
        "        ## A third pair of Dense Block and Transition Block where the number of\n",
        "        ## layers in the Dense Block are 24.\n",
        "        self.dense3 = self._make_dense_layers(denseLayer, num_planes, nblocks[2])\n",
        "        num_planes += nblocks[2]*growth_rate\n",
        "        out_planes = int(math.floor(num_planes*reduction))\n",
        "        self.trans3 = Transition(num_planes, out_planes)\n",
        "        num_planes = out_planes\n",
        "\n",
        "        ## Final Dense Block with 16 layers.\n",
        "        self.dense4 = self._make_dense_layers(denseLayer, num_planes, nblocks[3])\n",
        "        num_planes += nblocks[3]*growth_rate\n",
        "\n",
        "        ## Batch Normalization followed by Fully Connected layer for image classification.\n",
        "        self.bn = nn.BatchNorm2d(num_planes)\n",
        "        self.linear = nn.Linear(num_planes, num_classes)\n",
        "\n",
        "\n",
        "    def _make_dense_layers(self, denseLayer, in_planes, nblock):\n",
        "        \"\"\"\n",
        "        A method to construct Dense Block by utilizing the Bottleneck architecture.\n",
        "\n",
        "        Arguements\n",
        "        ----------\n",
        "        denseLayer => Name of the architecture to be used for constructing layers of Dense Block, i.e. Bottleneck.\n",
        "        in_planes  => Number of input channels.\n",
        "        nblock     => Number of layers to be constructed for a Dene Block.\n",
        "        \"\"\"\n",
        "        layers = []\n",
        "        for i in range(nblock):\n",
        "            layers.append(denseLayer(in_planes, self.growth_rate))\n",
        "            in_planes += self.growth_rate\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        A method to for compute the forward propagation of the DenseNet model.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        x => Input to the model.\n",
        "        \"\"\"\n",
        "        out = self.conv1(x)\n",
        "        out = self.trans1(self.dense1(out))\n",
        "        out = self.trans2(self.dense2(out))\n",
        "        out = self.trans3(self.dense3(out))\n",
        "        out = self.dense4(out)\n",
        "        out = F.avg_pool2d(F.relu(self.bn(out)), 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml5DI5caHInV",
        "colab_type": "text"
      },
      "source": [
        "# CIFAR10 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpLWE31FIx4n",
        "colab_type": "text"
      },
      "source": [
        "This section:\n",
        "\n",
        "1.   Downloads the CIFAR10 dataset from torchvision.datasets.\n",
        "2.   Performs pre-processing on downloaded image data by converting to tensors and normalizing them.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKqLwMdCk-hZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "832a2d41de75416099ab80ed75e44fa3",
            "a21b738373df4f42b03c70678f461e1d",
            "6d28be25121641a484c7f4a83d98bad2",
            "7e4fddf24dac4abda16f7f0aa3fb0b83",
            "57da882f0f7347c2b77866bf490c1ac8",
            "6ddf5c7b0cbb4df89fb50af96dc85a2d",
            "c743b3d77bf345cab4e5bfff7951551b",
            "7cbcc182d272487c84219b417869d691"
          ]
        },
        "outputId": "e154d1df-1505-4dce-e2ed-08697942d4e4"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "832a2d41de75416099ab80ed75e44fa3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp_UFlhvfZRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbFs1CcHUOZ",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDnMbjdcEcLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "2b3b92df-6e28-4ea5-be71-71e7f3d13f7f"
      },
      "source": [
        "# GPU Details\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul 13 14:19:36 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    29W /  70W |   1381MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVpPW41vr5pW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(outputs, labels):\n",
        "  \"\"\"\n",
        "  A function to compute the loss between predicted and true labels.\n",
        "\n",
        "  Arguements\n",
        "  ----------\n",
        "  outputs => Model predictions\n",
        "  labels  => True labels.\n",
        "  \"\"\"\n",
        "\n",
        "  return nn.CrossEntropyLoss()(outputs, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k437Hxwyq5yV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_loop_function(data_loader, model, optimizer, device):\n",
        "  \"\"\"\n",
        "  A function to implement the training loop over the training dataset.\n",
        "  \n",
        "  Arguments\n",
        "  ---------\n",
        "  data_loader => Data Loader containing the training data.\n",
        "  model       => DenseNet model to be trained.\n",
        "  optimizer   => Optimizer for the loss function.\n",
        "  device      => Represents the device used for training (CPU/GPU).\n",
        "  \"\"\"\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for bi, data in enumerate(data_loader):\n",
        "    inputs, labels = data\n",
        "    inputs = Variable(inputs).to(device)\n",
        "    labels = Variable(labels).to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if bi%50 == 0 and bi!=0:\n",
        "      temp = f'Batch index = {bi}\\tLoss = {running_loss/50}'\n",
        "      print(temp)\n",
        "\n",
        "      f1 = open('loss.txt', 'a+')\n",
        "      temp = temp + '\\n'\n",
        "      f1.write(temp)\n",
        "      f1.close()\n",
        "\n",
        "      running_loss = 0.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqaTNv08ujih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testing_loop_function(data_loader, model, device):\n",
        "  \"\"\"\n",
        "  A function to implement the testing loop over the test dataset and computing\n",
        "  the accuracy of the trained model.\n",
        "\n",
        "  Arguments\n",
        "  ---------\n",
        "  data_loader => Data Loader containing the test dataset.\n",
        "  model       => Trained model to be tested.\n",
        "  device      => Represents the device used for testing (CPU/GPU).\n",
        "  \"\"\"\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for data in data_loader:\n",
        "    inputs, labels = data\n",
        "    inputs = Variable(inputs).to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    outputs = outputs.cpu()\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    # print(f'Predicted = {predicted}\\nLabels = {labels}')\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "  print(f'\\nCorrect = {correct}\\tTotal = {total}')\n",
        "  if total != 0:\n",
        "    accuracy = (float(correct)/total)*100\n",
        "  else:\n",
        "    accuracy = 0\n",
        "\n",
        "  print(f'Accuracy = {accuracy}%\\n')\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi5OPIk5lF9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "TRAIN_BATCH_SIZE = 20\n",
        "TEST_BATCH_SIZE = 10\n",
        "EPOCHS = 10\n",
        "NUMBER_OF_CLASSES = 10\n",
        "LEARNING_RATE = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Lj-JYlnESJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constructing training and testing data loader. \n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = TRAIN_BATCH_SIZE,\n",
        "    shuffle = True, \n",
        "    num_workers = 4)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = TEST_BATCH_SIZE,\n",
        "    shuffle = True,\n",
        "    num_workers = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhMdC7psngjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d58c2ff1-1813-4778-9204-ee95f61ce180"
      },
      "source": [
        "print(f'Training set size = {len(train_data_loader)}')\n",
        "print(f'Testing set size = {len(test_data_loader)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size = 2500\n",
            "Testing set size = 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAc91S8bnxT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74f44d85-40d9-4ef8-c091-0b5b1c611e1c"
      },
      "source": [
        "# Selecting the device.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device = {device}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device = cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEyrZ2e-n7hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DenseNet(Bottleneck, [6,12,24,16], growth_rate=12)\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9NOy1r7pn7n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81424b74-4e49-4981-af91-d27ae821e2c0"
      },
      "source": [
        "start = time.time()\n",
        "for epoch in range(EPOCHS):\n",
        "  training_loop_function(train_data_loader, model, optimizer, device)\n",
        "  \n",
        "  accuracy = testing_loop_function(test_data_loader, model, device)\n",
        "  testing_accuracies.append(accuracy)\n",
        "  torch.save(model, 'Pre-Trained DenseNet Models/Epoch' + str(epoch) + '.bin')\n",
        "\n",
        "end = time.time()\n",
        "print(f'Total time = {(end-start)/60} minutes')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch index = 50\tLoss = 1.2379081773757934\n",
            "Batch index = 100\tLoss = 1.0912002265453338\n",
            "Batch index = 150\tLoss = 1.1317026901245117\n",
            "Batch index = 200\tLoss = 1.2060582339763641\n",
            "Batch index = 250\tLoss = 1.0855933332443237\n",
            "Batch index = 300\tLoss = 1.1300887978076934\n",
            "Batch index = 350\tLoss = 1.0923901629447936\n",
            "Batch index = 400\tLoss = 1.1051630532741548\n",
            "Batch index = 450\tLoss = 1.0490447652339936\n",
            "Batch index = 500\tLoss = 1.0308772397041321\n",
            "Batch index = 550\tLoss = 1.0134735119342804\n",
            "Batch index = 600\tLoss = 1.0888130581378936\n",
            "Batch index = 650\tLoss = 1.0306979483366012\n",
            "Batch index = 700\tLoss = 0.9881055080890655\n",
            "Batch index = 750\tLoss = 0.9934396374225617\n",
            "Batch index = 800\tLoss = 0.977533872127533\n",
            "Batch index = 850\tLoss = 0.9787932795286178\n",
            "Batch index = 900\tLoss = 0.9620926904678345\n",
            "Batch index = 950\tLoss = 0.9869308066368103\n",
            "Batch index = 1000\tLoss = 1.0038587683439255\n",
            "Batch index = 1050\tLoss = 0.9163251012563706\n",
            "Batch index = 1100\tLoss = 0.9379232889413833\n",
            "Batch index = 1150\tLoss = 1.00988616168499\n",
            "Batch index = 1200\tLoss = 0.9418018138408661\n",
            "Batch index = 1250\tLoss = 0.9437965726852418\n",
            "Batch index = 1300\tLoss = 0.9515809911489487\n",
            "Batch index = 1350\tLoss = 0.9215964663028717\n",
            "Batch index = 1400\tLoss = 0.9676185274124145\n",
            "Batch index = 1450\tLoss = 0.9183913099765778\n",
            "Batch index = 1500\tLoss = 0.9528587311506271\n",
            "Batch index = 1550\tLoss = 0.9328338718414306\n",
            "Batch index = 1600\tLoss = 0.9283595329523087\n",
            "Batch index = 1650\tLoss = 0.8924495470523834\n",
            "Batch index = 1700\tLoss = 0.9988340556621551\n",
            "Batch index = 1750\tLoss = 0.9232961040735245\n",
            "Batch index = 1800\tLoss = 0.8572939395904541\n",
            "Batch index = 1850\tLoss = 0.8338012021780014\n",
            "Batch index = 1900\tLoss = 0.8775407457351685\n",
            "Batch index = 1950\tLoss = 0.9303511720895767\n",
            "Batch index = 2000\tLoss = 0.874438379406929\n",
            "Batch index = 2050\tLoss = 0.8937268608808517\n",
            "Batch index = 2100\tLoss = 0.9005483776330948\n",
            "Batch index = 2150\tLoss = 0.9366193056106568\n",
            "Batch index = 2200\tLoss = 0.9078567880392074\n",
            "Batch index = 2250\tLoss = 0.8569801688194275\n",
            "Batch index = 2300\tLoss = 0.872691605091095\n",
            "Batch index = 2350\tLoss = 0.8035080051422119\n",
            "Batch index = 2400\tLoss = 0.9482903635501861\n",
            "Batch index = 2450\tLoss = 0.8528525203466415\n",
            "\n",
            "Correct = 6382\tTotal = 10000\n",
            "Accuracy = 63.82%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type DenseNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Bottleneck. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Transition. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch index = 50\tLoss = 0.7555076712369919\n",
            "Batch index = 100\tLoss = 0.7355345523357392\n",
            "Batch index = 150\tLoss = 0.6836469519138336\n",
            "Batch index = 200\tLoss = 0.8202556383609771\n",
            "Batch index = 250\tLoss = 0.7304655772447586\n",
            "Batch index = 300\tLoss = 0.7895811396837235\n",
            "Batch index = 350\tLoss = 0.7737535828351975\n",
            "Batch index = 400\tLoss = 0.7411657029390335\n",
            "Batch index = 450\tLoss = 0.7669126921892166\n",
            "Batch index = 500\tLoss = 0.7407006359100342\n",
            "Batch index = 550\tLoss = 0.7643030899763107\n",
            "Batch index = 600\tLoss = 0.7670738053321838\n",
            "Batch index = 650\tLoss = 0.6904565501213074\n",
            "Batch index = 700\tLoss = 0.748568748831749\n",
            "Batch index = 750\tLoss = 0.7275595307350159\n",
            "Batch index = 800\tLoss = 0.7869824385643005\n",
            "Batch index = 850\tLoss = 0.7101641434431076\n",
            "Batch index = 900\tLoss = 0.7383596873283387\n",
            "Batch index = 950\tLoss = 0.6900921958684921\n",
            "Batch index = 1000\tLoss = 0.695888090133667\n",
            "Batch index = 1050\tLoss = 0.6431792521476746\n",
            "Batch index = 1100\tLoss = 0.6776600253582\n",
            "Batch index = 1150\tLoss = 0.7169932281970978\n",
            "Batch index = 1200\tLoss = 0.6913108956813813\n",
            "Batch index = 1250\tLoss = 0.6938696813583374\n",
            "Batch index = 1300\tLoss = 0.7248157012462616\n",
            "Batch index = 1350\tLoss = 0.7243175441026688\n",
            "Batch index = 1400\tLoss = 0.6961986672878265\n",
            "Batch index = 1450\tLoss = 0.6825859880447388\n",
            "Batch index = 1500\tLoss = 0.7258252680301667\n",
            "Batch index = 1550\tLoss = 0.6728215563297272\n",
            "Batch index = 1600\tLoss = 0.6509695994853973\n",
            "Batch index = 1650\tLoss = 0.6722292718291283\n",
            "Batch index = 1700\tLoss = 0.6487707054615021\n",
            "Batch index = 1750\tLoss = 0.7718952852487564\n",
            "Batch index = 1800\tLoss = 0.6577855217456817\n",
            "Batch index = 1850\tLoss = 0.6838956320285797\n",
            "Batch index = 1900\tLoss = 0.6540280377864838\n",
            "Batch index = 1950\tLoss = 0.693742402791977\n",
            "Batch index = 2000\tLoss = 0.680540400147438\n",
            "Batch index = 2050\tLoss = 0.7257660913467407\n",
            "Batch index = 2100\tLoss = 0.6799835592508316\n",
            "Batch index = 2150\tLoss = 0.6830612307786942\n",
            "Batch index = 2200\tLoss = 0.668840059041977\n",
            "Batch index = 2250\tLoss = 0.6292303335666657\n",
            "Batch index = 2300\tLoss = 0.5889171099662781\n",
            "Batch index = 2350\tLoss = 0.6535507768392563\n",
            "Batch index = 2400\tLoss = 0.6198813265562058\n",
            "Batch index = 2450\tLoss = 0.6039567765593529\n",
            "\n",
            "Correct = 7706\tTotal = 10000\n",
            "Accuracy = 77.06%\n",
            "\n",
            "Batch index = 50\tLoss = 0.6089072778820992\n",
            "Batch index = 100\tLoss = 0.5504592615365982\n",
            "Batch index = 150\tLoss = 0.5453108811378479\n",
            "Batch index = 200\tLoss = 0.5763359886407852\n",
            "Batch index = 250\tLoss = 0.5281425088644027\n",
            "Batch index = 300\tLoss = 0.5357447651028633\n",
            "Batch index = 350\tLoss = 0.5512988576292992\n",
            "Batch index = 400\tLoss = 0.5925622984766961\n",
            "Batch index = 450\tLoss = 0.6078114882111549\n",
            "Batch index = 500\tLoss = 0.5553231924772263\n",
            "Batch index = 550\tLoss = 0.5956861174106598\n",
            "Batch index = 600\tLoss = 0.556626843214035\n",
            "Batch index = 650\tLoss = 0.5446936467289925\n",
            "Batch index = 700\tLoss = 0.582187668979168\n",
            "Batch index = 750\tLoss = 0.5541116288304329\n",
            "Batch index = 800\tLoss = 0.5770510420203209\n",
            "Batch index = 850\tLoss = 0.5705735900998116\n",
            "Batch index = 900\tLoss = 0.552472140789032\n",
            "Batch index = 950\tLoss = 0.5746846550703049\n",
            "Batch index = 1000\tLoss = 0.5550262188911438\n",
            "Batch index = 1050\tLoss = 0.5418360778689384\n",
            "Batch index = 1100\tLoss = 0.5602519768476486\n",
            "Batch index = 1150\tLoss = 0.5844089621305466\n",
            "Batch index = 1200\tLoss = 0.5347369867563248\n",
            "Batch index = 1250\tLoss = 0.55741165548563\n",
            "Batch index = 1300\tLoss = 0.4958223347365856\n",
            "Batch index = 1350\tLoss = 0.5324236452579498\n",
            "Batch index = 1400\tLoss = 0.5607762292027474\n",
            "Batch index = 1450\tLoss = 0.5786980539560318\n",
            "Batch index = 1500\tLoss = 0.5071638682484627\n",
            "Batch index = 1550\tLoss = 0.5545509114861489\n",
            "Batch index = 1600\tLoss = 0.570106825530529\n",
            "Batch index = 1650\tLoss = 0.4852772882580757\n",
            "Batch index = 1700\tLoss = 0.56843544870615\n",
            "Batch index = 1750\tLoss = 0.5302983608841896\n",
            "Batch index = 1800\tLoss = 0.5528100767731666\n",
            "Batch index = 1850\tLoss = 0.461859160810709\n",
            "Batch index = 1900\tLoss = 0.510762196779251\n",
            "Batch index = 1950\tLoss = 0.5110268756747246\n",
            "Batch index = 2000\tLoss = 0.5869238495826721\n",
            "Batch index = 2050\tLoss = 0.5477558758854866\n",
            "Batch index = 2100\tLoss = 0.5676062798500061\n",
            "Batch index = 2150\tLoss = 0.5701826196908951\n",
            "Batch index = 2200\tLoss = 0.5458437079191207\n",
            "Batch index = 2250\tLoss = 0.5824349772930145\n",
            "Batch index = 2300\tLoss = 0.6146347433328628\n",
            "Batch index = 2350\tLoss = 0.49108199805021285\n",
            "Batch index = 2400\tLoss = 0.5014337855577469\n",
            "Batch index = 2450\tLoss = 0.5451972416043281\n",
            "\n",
            "Correct = 8161\tTotal = 10000\n",
            "Accuracy = 81.61%\n",
            "\n",
            "Batch index = 50\tLoss = 0.47724386245012285\n",
            "Batch index = 100\tLoss = 0.4394044840335846\n",
            "Batch index = 150\tLoss = 0.4432985010743141\n",
            "Batch index = 200\tLoss = 0.4854694017767906\n",
            "Batch index = 250\tLoss = 0.39743364945054055\n",
            "Batch index = 300\tLoss = 0.48265440195798875\n",
            "Batch index = 350\tLoss = 0.4850325280427933\n",
            "Batch index = 400\tLoss = 0.5085557863116265\n",
            "Batch index = 450\tLoss = 0.45236442863941195\n",
            "Batch index = 500\tLoss = 0.4169817793369293\n",
            "Batch index = 550\tLoss = 0.43756845146417617\n",
            "Batch index = 600\tLoss = 0.4753312355279922\n",
            "Batch index = 650\tLoss = 0.4718543604761362\n",
            "Batch index = 700\tLoss = 0.4225586502254009\n",
            "Batch index = 750\tLoss = 0.5484715214371682\n",
            "Batch index = 800\tLoss = 0.5096580010652542\n",
            "Batch index = 850\tLoss = 0.4797624260187149\n",
            "Batch index = 900\tLoss = 0.4577489000558853\n",
            "Batch index = 950\tLoss = 0.4782468505203724\n",
            "Batch index = 1000\tLoss = 0.43052954018115996\n",
            "Batch index = 1050\tLoss = 0.4413193839788437\n",
            "Batch index = 1100\tLoss = 0.43484009444713595\n",
            "Batch index = 1150\tLoss = 0.4502894127368927\n",
            "Batch index = 1200\tLoss = 0.45286857783794404\n",
            "Batch index = 1250\tLoss = 0.42226589053869246\n",
            "Batch index = 1300\tLoss = 0.39465039372444155\n",
            "Batch index = 1350\tLoss = 0.46492327749729156\n",
            "Batch index = 1400\tLoss = 0.44894345819950104\n",
            "Batch index = 1450\tLoss = 0.4262856158614159\n",
            "Batch index = 1500\tLoss = 0.48569506883621216\n",
            "Batch index = 1550\tLoss = 0.5122140699625015\n",
            "Batch index = 1600\tLoss = 0.49789994448423386\n",
            "Batch index = 1650\tLoss = 0.49340088069438937\n",
            "Batch index = 1700\tLoss = 0.4512301915884018\n",
            "Batch index = 1750\tLoss = 0.4521599704027176\n",
            "Batch index = 1800\tLoss = 0.45506014734506606\n",
            "Batch index = 1850\tLoss = 0.4572380369901657\n",
            "Batch index = 1900\tLoss = 0.5376638320088386\n",
            "Batch index = 1950\tLoss = 0.4990933778882027\n",
            "Batch index = 2000\tLoss = 0.42730324357748034\n",
            "Batch index = 2050\tLoss = 0.45698515117168426\n",
            "Batch index = 2100\tLoss = 0.45441292762756347\n",
            "Batch index = 2150\tLoss = 0.44753543272614477\n",
            "Batch index = 2200\tLoss = 0.4824876680970192\n",
            "Batch index = 2250\tLoss = 0.4431473933160305\n",
            "Batch index = 2300\tLoss = 0.3844121006131172\n",
            "Batch index = 2350\tLoss = 0.44441682696342466\n",
            "Batch index = 2400\tLoss = 0.5028388552367687\n",
            "Batch index = 2450\tLoss = 0.49594412207603455\n",
            "\n",
            "Correct = 8283\tTotal = 10000\n",
            "Accuracy = 82.83%\n",
            "\n",
            "Batch index = 50\tLoss = 0.35033615946769714\n",
            "Batch index = 100\tLoss = 0.38690940365195275\n",
            "Batch index = 150\tLoss = 0.3443963071703911\n",
            "Batch index = 200\tLoss = 0.38526000052690507\n",
            "Batch index = 250\tLoss = 0.375517211407423\n",
            "Batch index = 300\tLoss = 0.3653879202902317\n",
            "Batch index = 350\tLoss = 0.39939398258924486\n",
            "Batch index = 400\tLoss = 0.3857870787382126\n",
            "Batch index = 450\tLoss = 0.3758352816104889\n",
            "Batch index = 500\tLoss = 0.3922229258716106\n",
            "Batch index = 550\tLoss = 0.40347467333078385\n",
            "Batch index = 600\tLoss = 0.43659009903669355\n",
            "Batch index = 650\tLoss = 0.36234589442610743\n",
            "Batch index = 700\tLoss = 0.33273540750145914\n",
            "Batch index = 750\tLoss = 0.3628078344464302\n",
            "Batch index = 800\tLoss = 0.375285410284996\n",
            "Batch index = 850\tLoss = 0.4218343498557806\n",
            "Batch index = 900\tLoss = 0.3840155807137489\n",
            "Batch index = 950\tLoss = 0.4453469602763653\n",
            "Batch index = 1000\tLoss = 0.46208136171102526\n",
            "Batch index = 1050\tLoss = 0.41427376478910444\n",
            "Batch index = 1100\tLoss = 0.41119577929377554\n",
            "Batch index = 1150\tLoss = 0.3648450407385826\n",
            "Batch index = 1200\tLoss = 0.37876118466258046\n",
            "Batch index = 1250\tLoss = 0.41926550775766375\n",
            "Batch index = 1300\tLoss = 0.43712522998452186\n",
            "Batch index = 1350\tLoss = 0.35207686334848404\n",
            "Batch index = 1400\tLoss = 0.38247147768735884\n",
            "Batch index = 1450\tLoss = 0.3902399228513241\n",
            "Batch index = 1500\tLoss = 0.377126384973526\n",
            "Batch index = 1550\tLoss = 0.3698478324711323\n",
            "Batch index = 1600\tLoss = 0.4226033081114292\n",
            "Batch index = 1650\tLoss = 0.3568212006241083\n",
            "Batch index = 1700\tLoss = 0.40734806418418884\n",
            "Batch index = 1750\tLoss = 0.42081952959299085\n",
            "Batch index = 1800\tLoss = 0.419480265378952\n",
            "Batch index = 1850\tLoss = 0.4052203342318535\n",
            "Batch index = 1900\tLoss = 0.3873725739121437\n",
            "Batch index = 1950\tLoss = 0.3981826364994049\n",
            "Batch index = 2000\tLoss = 0.4017051848769188\n",
            "Batch index = 2050\tLoss = 0.38007660537958143\n",
            "Batch index = 2100\tLoss = 0.3608279363811016\n",
            "Batch index = 2150\tLoss = 0.36204151675105095\n",
            "Batch index = 2200\tLoss = 0.40366672292351724\n",
            "Batch index = 2250\tLoss = 0.3737140691280365\n",
            "Batch index = 2300\tLoss = 0.3883455742895603\n",
            "Batch index = 2350\tLoss = 0.4444487062096596\n",
            "Batch index = 2400\tLoss = 0.41253047332167625\n",
            "Batch index = 2450\tLoss = 0.3934318208694458\n",
            "\n",
            "Correct = 8496\tTotal = 10000\n",
            "Accuracy = 84.96000000000001%\n",
            "\n",
            "Batch index = 50\tLoss = 0.3214877372980118\n",
            "Batch index = 100\tLoss = 0.2919547089189291\n",
            "Batch index = 150\tLoss = 0.3211413371562958\n",
            "Batch index = 200\tLoss = 0.32618587255477904\n",
            "Batch index = 250\tLoss = 0.2874259252846241\n",
            "Batch index = 300\tLoss = 0.3425849413871765\n",
            "Batch index = 350\tLoss = 0.2884965102374554\n",
            "Batch index = 400\tLoss = 0.3396384629607201\n",
            "Batch index = 450\tLoss = 0.3714831179380417\n",
            "Batch index = 500\tLoss = 0.34275379180908205\n",
            "Batch index = 550\tLoss = 0.34310724765062334\n",
            "Batch index = 600\tLoss = 0.31262787044048307\n",
            "Batch index = 650\tLoss = 0.2756346333026886\n",
            "Batch index = 700\tLoss = 0.3021414618939161\n",
            "Batch index = 750\tLoss = 0.3122246481478214\n",
            "Batch index = 800\tLoss = 0.3415550161898136\n",
            "Batch index = 850\tLoss = 0.2852176398783922\n",
            "Batch index = 900\tLoss = 0.35408400893211367\n",
            "Batch index = 950\tLoss = 0.33466986551880834\n",
            "Batch index = 1000\tLoss = 0.322081662863493\n",
            "Batch index = 1050\tLoss = 0.3271251775324345\n",
            "Batch index = 1100\tLoss = 0.3103905748575926\n",
            "Batch index = 1150\tLoss = 0.3448422893881798\n",
            "Batch index = 1200\tLoss = 0.3663879507780075\n",
            "Batch index = 1250\tLoss = 0.3403071953356266\n",
            "Batch index = 1300\tLoss = 0.3495449663698673\n",
            "Batch index = 1350\tLoss = 0.3657517369091511\n",
            "Batch index = 1400\tLoss = 0.3048406907916069\n",
            "Batch index = 1450\tLoss = 0.34081875629723074\n",
            "Batch index = 1500\tLoss = 0.33052692376077175\n",
            "Batch index = 1550\tLoss = 0.3768829445540905\n",
            "Batch index = 1600\tLoss = 0.2883514839410782\n",
            "Batch index = 1650\tLoss = 0.3730285336077213\n",
            "Batch index = 1700\tLoss = 0.3618877539038658\n",
            "Batch index = 1750\tLoss = 0.348200806081295\n",
            "Batch index = 1800\tLoss = 0.3434174081683159\n",
            "Batch index = 1850\tLoss = 0.3470107003301382\n",
            "Batch index = 1900\tLoss = 0.32429647460579875\n",
            "Batch index = 1950\tLoss = 0.29868467658758163\n",
            "Batch index = 2000\tLoss = 0.35271821036934853\n",
            "Batch index = 2050\tLoss = 0.36541921593248844\n",
            "Batch index = 2100\tLoss = 0.33425814121961595\n",
            "Batch index = 2150\tLoss = 0.3269131118059158\n",
            "Batch index = 2200\tLoss = 0.3383626795560122\n",
            "Batch index = 2250\tLoss = 0.34358634896576407\n",
            "Batch index = 2300\tLoss = 0.30109135195612907\n",
            "Batch index = 2350\tLoss = 0.3305490605533123\n",
            "Batch index = 2400\tLoss = 0.3564482324570417\n",
            "Batch index = 2450\tLoss = 0.3294309259951115\n",
            "\n",
            "Correct = 8506\tTotal = 10000\n",
            "Accuracy = 85.06%\n",
            "\n",
            "Batch index = 50\tLoss = 0.27084253296256067\n",
            "Batch index = 100\tLoss = 0.22585207119584083\n",
            "Batch index = 150\tLoss = 0.2064473281800747\n",
            "Batch index = 200\tLoss = 0.2565245894342661\n",
            "Batch index = 250\tLoss = 0.24918533734977244\n",
            "Batch index = 300\tLoss = 0.2694576855003834\n",
            "Batch index = 350\tLoss = 0.25604060031473636\n",
            "Batch index = 400\tLoss = 0.29964961104094984\n",
            "Batch index = 450\tLoss = 0.28630312874913216\n",
            "Batch index = 500\tLoss = 0.2555511197447777\n",
            "Batch index = 550\tLoss = 0.3049129420518875\n",
            "Batch index = 600\tLoss = 0.307956330627203\n",
            "Batch index = 650\tLoss = 0.24823771879076958\n",
            "Batch index = 700\tLoss = 0.3182389818131924\n",
            "Batch index = 750\tLoss = 0.2975334902107716\n",
            "Batch index = 800\tLoss = 0.2698743158578873\n",
            "Batch index = 850\tLoss = 0.28557005763053894\n",
            "Batch index = 900\tLoss = 0.2975855557247996\n",
            "Batch index = 950\tLoss = 0.22693055000156165\n",
            "Batch index = 1000\tLoss = 0.26831899404525755\n",
            "Batch index = 1050\tLoss = 0.25065297476947307\n",
            "Batch index = 1100\tLoss = 0.28512080781161786\n",
            "Batch index = 1150\tLoss = 0.2703540141880512\n",
            "Batch index = 1200\tLoss = 0.267128394395113\n",
            "Batch index = 1250\tLoss = 0.31901426702737806\n",
            "Batch index = 1300\tLoss = 0.3399314280599356\n",
            "Batch index = 1350\tLoss = 0.32524045154452325\n",
            "Batch index = 1400\tLoss = 0.24767248079180718\n",
            "Batch index = 1450\tLoss = 0.26550315886735915\n",
            "Batch index = 1500\tLoss = 0.29839771285653116\n",
            "Batch index = 1550\tLoss = 0.32820201478898525\n",
            "Batch index = 1600\tLoss = 0.29297102965414523\n",
            "Batch index = 1650\tLoss = 0.3054551726579666\n",
            "Batch index = 1700\tLoss = 0.29190776638686655\n",
            "Batch index = 1750\tLoss = 0.26851503401994703\n",
            "Batch index = 1800\tLoss = 0.28957620441913606\n",
            "Batch index = 1850\tLoss = 0.30466105103492735\n",
            "Batch index = 1900\tLoss = 0.3097115110605955\n",
            "Batch index = 1950\tLoss = 0.2463652114570141\n",
            "Batch index = 2000\tLoss = 0.22862497866153716\n",
            "Batch index = 2050\tLoss = 0.2572732309252024\n",
            "Batch index = 2100\tLoss = 0.30019617818295957\n",
            "Batch index = 2150\tLoss = 0.32784180104732513\n",
            "Batch index = 2200\tLoss = 0.29034003987908363\n",
            "Batch index = 2250\tLoss = 0.2881688576191664\n",
            "Batch index = 2300\tLoss = 0.3181311641633511\n",
            "Batch index = 2350\tLoss = 0.26894024059176447\n",
            "Batch index = 2400\tLoss = 0.28306645348668097\n",
            "Batch index = 2450\tLoss = 0.2696166065707803\n",
            "\n",
            "Correct = 8549\tTotal = 10000\n",
            "Accuracy = 85.49%\n",
            "\n",
            "Batch index = 50\tLoss = 0.17792676169425248\n",
            "Batch index = 100\tLoss = 0.22999153085052967\n",
            "Batch index = 150\tLoss = 0.18531067442148924\n",
            "Batch index = 200\tLoss = 0.14043768014758826\n",
            "Batch index = 250\tLoss = 0.20894737131893634\n",
            "Batch index = 300\tLoss = 0.24139717683196069\n",
            "Batch index = 350\tLoss = 0.19974256809800864\n",
            "Batch index = 400\tLoss = 0.22006456054747103\n",
            "Batch index = 450\tLoss = 0.23000582613050938\n",
            "Batch index = 500\tLoss = 0.21486501965671778\n",
            "Batch index = 550\tLoss = 0.24279916599392892\n",
            "Batch index = 600\tLoss = 0.21907245922833682\n",
            "Batch index = 650\tLoss = 0.19647543244063853\n",
            "Batch index = 700\tLoss = 0.18192064687609671\n",
            "Batch index = 750\tLoss = 0.2700098066031933\n",
            "Batch index = 800\tLoss = 0.27297091903164983\n",
            "Batch index = 850\tLoss = 0.26302922777831556\n",
            "Batch index = 900\tLoss = 0.2625958722084761\n",
            "Batch index = 950\tLoss = 0.21354065254330634\n",
            "Batch index = 1000\tLoss = 0.20764631275087594\n",
            "Batch index = 1050\tLoss = 0.21823890767991544\n",
            "Batch index = 1100\tLoss = 0.25431612215936183\n",
            "Batch index = 1150\tLoss = 0.2333128383010626\n",
            "Batch index = 1200\tLoss = 0.2446679383702576\n",
            "Batch index = 1250\tLoss = 0.22525879330933093\n",
            "Batch index = 1300\tLoss = 0.3081583822518587\n",
            "Batch index = 1350\tLoss = 0.2355727081373334\n",
            "Batch index = 1400\tLoss = 0.25750873655080797\n",
            "Batch index = 1450\tLoss = 0.22836477667093277\n",
            "Batch index = 1500\tLoss = 0.2596320697665215\n",
            "Batch index = 1550\tLoss = 0.2566488605737686\n",
            "Batch index = 1600\tLoss = 0.27453879624605176\n",
            "Batch index = 1650\tLoss = 0.23808942593634128\n",
            "Batch index = 1700\tLoss = 0.22307773426175118\n",
            "Batch index = 1750\tLoss = 0.21991248451173306\n",
            "Batch index = 1800\tLoss = 0.26468043103814126\n",
            "Batch index = 1850\tLoss = 0.2597032631933689\n",
            "Batch index = 1900\tLoss = 0.29896243259310723\n",
            "Batch index = 1950\tLoss = 0.22869581483304502\n",
            "Batch index = 2000\tLoss = 0.2634521923214197\n",
            "Batch index = 2050\tLoss = 0.2491134362667799\n",
            "Batch index = 2100\tLoss = 0.2365548050403595\n",
            "Batch index = 2150\tLoss = 0.2766244393587112\n",
            "Batch index = 2200\tLoss = 0.22817628227174283\n",
            "Batch index = 2250\tLoss = 0.23696844920516014\n",
            "Batch index = 2300\tLoss = 0.2317526027560234\n",
            "Batch index = 2350\tLoss = 0.26703838758170606\n",
            "Batch index = 2400\tLoss = 0.2864771464839578\n",
            "Batch index = 2450\tLoss = 0.28442196883261206\n",
            "\n",
            "Correct = 8579\tTotal = 10000\n",
            "Accuracy = 85.79%\n",
            "\n",
            "Batch index = 50\tLoss = 0.14535176195204258\n",
            "Batch index = 100\tLoss = 0.15262680128216743\n",
            "Batch index = 150\tLoss = 0.14368249837309122\n",
            "Batch index = 200\tLoss = 0.16659017898142336\n",
            "Batch index = 250\tLoss = 0.15538433998823165\n",
            "Batch index = 300\tLoss = 0.1951494511961937\n",
            "Batch index = 350\tLoss = 0.20189013432711364\n",
            "Batch index = 400\tLoss = 0.1830908500030637\n",
            "Batch index = 450\tLoss = 0.20190173491835595\n",
            "Batch index = 500\tLoss = 0.2035549625568092\n",
            "Batch index = 550\tLoss = 0.1911065811663866\n",
            "Batch index = 600\tLoss = 0.18012469982728363\n",
            "Batch index = 650\tLoss = 0.20029775068163871\n",
            "Batch index = 700\tLoss = 0.21922726064920425\n",
            "Batch index = 750\tLoss = 0.18835376020520925\n",
            "Batch index = 800\tLoss = 0.2359422391653061\n",
            "Batch index = 850\tLoss = 0.20257165456190707\n",
            "Batch index = 900\tLoss = 0.18565010827034711\n",
            "Batch index = 950\tLoss = 0.18582527656108142\n",
            "Batch index = 1000\tLoss = 0.18665558740496635\n",
            "Batch index = 1050\tLoss = 0.21384155482053757\n",
            "Batch index = 1100\tLoss = 0.1812408471852541\n",
            "Batch index = 1150\tLoss = 0.2455115176923573\n",
            "Batch index = 1200\tLoss = 0.21132642474025487\n",
            "Batch index = 1250\tLoss = 0.21605067770928144\n",
            "Batch index = 1300\tLoss = 0.18358284656889737\n",
            "Batch index = 1350\tLoss = 0.21048981346189977\n",
            "Batch index = 1400\tLoss = 0.21159101016819476\n",
            "Batch index = 1450\tLoss = 0.22455986965447663\n",
            "Batch index = 1500\tLoss = 0.22511771626770496\n",
            "Batch index = 1550\tLoss = 0.16832679968327283\n",
            "Batch index = 1600\tLoss = 0.1732113552838564\n",
            "Batch index = 1650\tLoss = 0.22355964563786984\n",
            "Batch index = 1700\tLoss = 0.21515284106135368\n",
            "Batch index = 1750\tLoss = 0.21136095866560936\n",
            "Batch index = 1800\tLoss = 0.23569549318403005\n",
            "Batch index = 1850\tLoss = 0.22900241285562514\n",
            "Batch index = 1900\tLoss = 0.2496804841607809\n",
            "Batch index = 1950\tLoss = 0.20852915152907373\n",
            "Batch index = 2000\tLoss = 0.20148221507668496\n",
            "Batch index = 2050\tLoss = 0.2247312644124031\n",
            "Batch index = 2100\tLoss = 0.23322663707658647\n",
            "Batch index = 2150\tLoss = 0.22170493885874748\n",
            "Batch index = 2200\tLoss = 0.20869304209947587\n",
            "Batch index = 2250\tLoss = 0.2022718919813633\n",
            "Batch index = 2300\tLoss = 0.26460756480693814\n",
            "Batch index = 2350\tLoss = 0.19664745982736348\n",
            "Batch index = 2400\tLoss = 0.2268024430423975\n",
            "Batch index = 2450\tLoss = 0.22097000177949666\n",
            "\n",
            "Correct = 8625\tTotal = 10000\n",
            "Accuracy = 86.25%\n",
            "\n",
            "Batch index = 50\tLoss = 0.1463058413565159\n",
            "Batch index = 100\tLoss = 0.16035239074379207\n",
            "Batch index = 150\tLoss = 0.10453909054398537\n",
            "Batch index = 200\tLoss = 0.15009962271898986\n",
            "Batch index = 250\tLoss = 0.11342157641425729\n",
            "Batch index = 300\tLoss = 0.14031844338402152\n",
            "Batch index = 350\tLoss = 0.13508424907922745\n",
            "Batch index = 400\tLoss = 0.16858833659440278\n",
            "Batch index = 450\tLoss = 0.19390087217092514\n",
            "Batch index = 500\tLoss = 0.15646750941872598\n",
            "Batch index = 550\tLoss = 0.14900310395285488\n",
            "Batch index = 600\tLoss = 0.16456572320312263\n",
            "Batch index = 650\tLoss = 0.13745004504919053\n",
            "Batch index = 700\tLoss = 0.18658744944259525\n",
            "Batch index = 750\tLoss = 0.1680037935823202\n",
            "Batch index = 800\tLoss = 0.16010066658258437\n",
            "Batch index = 850\tLoss = 0.14455168026499451\n",
            "Batch index = 900\tLoss = 0.23068244626745582\n",
            "Batch index = 950\tLoss = 0.1834522257745266\n",
            "Batch index = 1000\tLoss = 0.16581445720046759\n",
            "Batch index = 1050\tLoss = 0.1609518806450069\n",
            "Batch index = 1100\tLoss = 0.17958911390975119\n",
            "Batch index = 1150\tLoss = 0.1719406471773982\n",
            "Batch index = 1200\tLoss = 0.17234615482389926\n",
            "Batch index = 1250\tLoss = 0.1721554619073868\n",
            "Batch index = 1300\tLoss = 0.17667796978726982\n",
            "Batch index = 1350\tLoss = 0.1591354108788073\n",
            "Batch index = 1400\tLoss = 0.22986600149422884\n",
            "Batch index = 1450\tLoss = 0.22699241034686565\n",
            "Batch index = 1500\tLoss = 0.16685325525701045\n",
            "Batch index = 1550\tLoss = 0.19307332571595906\n",
            "Batch index = 1600\tLoss = 0.2186258515715599\n",
            "Batch index = 1650\tLoss = 0.1877654776163399\n",
            "Batch index = 1700\tLoss = 0.16263344468548893\n",
            "Batch index = 1750\tLoss = 0.1647439419850707\n",
            "Batch index = 1800\tLoss = 0.1629992949590087\n",
            "Batch index = 1850\tLoss = 0.19818436954170465\n",
            "Batch index = 1900\tLoss = 0.14164634423330427\n",
            "Batch index = 1950\tLoss = 0.18989600092172623\n",
            "Batch index = 2000\tLoss = 0.21115530751645564\n",
            "Batch index = 2050\tLoss = 0.17679820753633976\n",
            "Batch index = 2100\tLoss = 0.15273047249764204\n",
            "Batch index = 2150\tLoss = 0.2193728969246149\n",
            "Batch index = 2200\tLoss = 0.19130582857877015\n",
            "Batch index = 2250\tLoss = 0.18751118622720242\n",
            "Batch index = 2300\tLoss = 0.1995753638073802\n",
            "Batch index = 2350\tLoss = 0.19763749539852143\n",
            "Batch index = 2400\tLoss = 0.1986126349493861\n",
            "Batch index = 2450\tLoss = 0.1711592344008386\n",
            "\n",
            "Correct = 8597\tTotal = 10000\n",
            "Accuracy = 85.97%\n",
            "\n",
            "Total time = 40.07794561386108 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2pE8iPRHkfq",
        "colab_type": "text"
      },
      "source": [
        "# Result and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVvmpWqpEB5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1 = open('loss.txt', 'r')\n",
        "data = f1.read().split('\\n')\n",
        "f1.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twTgreQw1KkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = []\n",
        "\n",
        "for each in data:\n",
        "  each = each.split('\\t')\n",
        "  temp = each[1].split(' = ')[1]\n",
        "  y.append(float(temp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxal0xul3XjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "14553499-0075-4553-d4c9-bece94e7085a"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = range(len(y))\n",
        "x_epoch = [z for z in range(1, len(y)+1) if (z%49)==0]\n",
        "x_ticks_labels = ['epoch' + str(x) for x in range(1, 11)]\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(x, y, color='k', label=\"Training Loss\")\n",
        "plt.xticks(x_epoch, x_ticks_labels, fontsize=7)\n",
        "plt.title(\"Training Error Plot\")\n",
        "plt.ylabel(\"Training error loss\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.legend()\n",
        "plt.savefig('training.png', dpi=300, figsize=(10, 20))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBkC3vrN5k0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d152f8f-28d2-4219-f287-db7cf5c7183f"
      },
      "source": [
        "x_epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[99, 198, 297, 396]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2iRTLCIHqdh",
        "colab_type": "text"
      },
      "source": [
        "# Model Latency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E42OJs1nAbp7",
        "colab_type": "text"
      },
      "source": [
        "This section computes the model latency.\n",
        "\n",
        "Instead of computing the latency based on a single batch, it is computed by averaging the latencies of 10 batches, to get a robust value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9ngYbIIR1la",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trained_model = torch.load('/content/DenseNETforCIFAR10-8.bin')\n",
        "trained_model.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-0T6OXRATQ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a96ac694-f99f-48d0-ed7d-2c5debc3ba02"
      },
      "source": [
        "# Batch Size = 1 image (3x32x32)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device: {device}')\n",
        "random_inputs = torch.randn(10, 1, 3, 32, 32)\n",
        "random_inputs = random_inputs.to(device)\n",
        "\n",
        "total_time = 0\n",
        "for input in random_inputs:\n",
        "  start = time.time()\n",
        "  outputs = trained_model(input)\n",
        "  end = time.time()\n",
        "\n",
        "  total_time += end - start\n",
        "\n",
        "print(f'Latency of the model for inferencing a single image\\'s class using \\\n",
        "        Tesla K80 = {total_time/10} seconds')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda:0\n",
            "Latency of the model for inferencing a single image's class using Tesla K80 = 0.03198542594909668 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiGEeJco7yh7",
        "colab_type": "text"
      },
      "source": [
        "# Exporting PyTorch Model to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UimTa37kBM6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load('/content/DenseNETforCIFAR10-8.bin')\n",
        "model.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZFlumcB-M0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "x = torch.randn(1, 3, 32, 32)\n",
        "x = x.to(device)\n",
        "torch_out = model(x)\n",
        "\n",
        "torch.onnx.export(model, x, \"denseNet.onnx\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}